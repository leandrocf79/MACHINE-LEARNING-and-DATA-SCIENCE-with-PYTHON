# -*- coding: utf-8 -*-
"""Machine Learning e Data Science com Python de A à Z - Classificação.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SnsJEDRxizpwff6K0JFEFHoBtXR5NT9y

# Machine Learning e Data Science com Python de A à Z (Classificacão) - IA Expert Academy
"""



"""# Importação das bibliotecas básicas"""

!pip -q install plotly --upgrade

!pip -q install yellowbrick

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

"""# Base de dados de crédito

- Fonte (adaptado): https://www.kaggle.com/laotse/credit-risk-dataset
"""

from google.colab import drive
drive.mount('/content/drive')

"""### Exploração dos dados"""

base_credit = pd.read_csv('/content/credit_data.csv')

base_credit # defaulted

base_credit.head(10)

base_credit.tail(8)

base_credit.describe()

base_credit[base_credit['income'] >= 69995.685578]

base_credit[base_credit['loan'] <= 1.377630]

"""### Visualização dos dados"""

np.unique(base_credit['default'], return_counts=True)

sns.countplot(x = base_credit['default']);

plt.hist(x = base_credit['age']);

plt.hist(x = base_credit['income']);

plt.hist(x = base_credit['loan']);

grafico = px.scatter_matrix(base_credit, dimensions=['age', 'income', 'loan'], color = 'default')
grafico.show()

"""### Tratamento de valores inconsistentes"""

base_credit.loc[base_credit['age'] < 0]

base_credit[base_credit['age'] < 0]

# Apagar a coluna inteira (de todos os registros da base de dados)
base_credit2 = base_credit.drop('age', axis = 1)
base_credit2

base_credit.index

base_credit[base_credit['age'] < 0].index

# Apagar somente os registros com valores inconsistentes
base_credit3 = base_credit.drop(base_credit[base_credit['age'] < 0].index)
base_credit3

base_credit3.loc[base_credit3['age'] < 0]

# Preencher os valores inconsistente manualmente

# Prencher a média

base_credit.mean()

base_credit['age'].mean()

base_credit['age'][base_credit['age'] > 0].mean()

base_credit.loc[base_credit['age'] < 0, 'age'] = 40.92

base_credit.loc[base_credit['age'] < 0]

base_credit.head(27)

"""### Tratamento de valores faltantes"""

base_credit.isnull()

base_credit.isnull().sum()

base_credit.loc[pd.isnull(base_credit['age'])]

base_credit['age'].fillna(base_credit['age'].mean(), inplace = True)

base_credit.loc[pd.isnull(base_credit['age'])]

base_credit.loc[(base_credit['clientid'] == 29) | (base_credit['clientid'] == 31) | (base_credit['clientid'] == 32)]

base_credit.loc[base_credit['clientid'].isin([29, 31, 32])]

"""### Divisão entre previsores e classe"""

type(base_credit)

X_credit = base_credit.iloc[:, 1:4].values

X_credit

type(X_credit)

y_credit = base_credit.iloc[:, 4].values

y_credit

type(y_credit)

"""### Escalonamento dos valores"""

X_credit

X_credit[:,0].min(), X_credit[:,1].min(), X_credit[:,2].min()

X_credit[:,0].max(), X_credit[:,1].max(), X_credit[:,2].max()

from sklearn.preprocessing import StandardScaler
scaler_credit = StandardScaler()
X_credit = scaler_credit.fit_transform(X_credit)

X_credit[:,0].min(), X_credit[:,1].min(), X_credit[:,2].min()

X_credit[:,0].max(), X_credit[:,1].max(), X_credit[:,2].max()

X_credit

"""# Base de dados do censo

- Fonte: https://archive.ics.uci.edu/ml/datasets/adult

## Exploração dos dados
"""

base_census = pd.read_csv('/content/census.csv')

base_census

base_census.describe()

base_census.isnull().sum()

"""## Visualização dos dados"""

np.unique(base_census['income'], return_counts=True)

sns.countplot(x = base_census['income']);

plt.hist(x = base_census['age']);

plt.hist(x = base_census['education-num']);

plt.hist(x = base_census['hour-per-week']);

grafico = px.treemap(base_census, path=['workclass', 'age'])
grafico.show()

grafico = px.treemap(base_census, path=['occupation', 'relationship', 'age'])
grafico.show()

grafico = px.parallel_categories(base_census, dimensions=['occupation', 'relationship'])
grafico.show()

grafico = px.parallel_categories(base_census, dimensions=['workclass', 'occupation', 'income'])
grafico.show()

grafico = px.parallel_categories(base_census, dimensions=['education', 'income'])
grafico.show()

"""## Divisão entre previsores e classe"""

base_census.columns

X_census = base_census.iloc[:, 0:14].values

X_census

X_census[0]

y_census = base_census.iloc[:, 14].values

y_census

"""## Tratamento de atributos categóricos

### LabelEncoder
"""

from sklearn.preprocessing import LabelEncoder

label_encoder_teste = LabelEncoder()

X_census[:,1]

teste = label_encoder_teste.fit_transform(X_census[:,1])

teste

X_census[0]

label_encoder_workclass = LabelEncoder()
label_encoder_education = LabelEncoder()
label_encoder_marital = LabelEncoder()
label_encoder_occupation = LabelEncoder()
label_encoder_relationship = LabelEncoder()
label_encoder_race = LabelEncoder()
label_encoder_sex = LabelEncoder()
label_encoder_country = LabelEncoder()

X_census[:,1] = label_encoder_workclass.fit_transform(X_census[:,1])
X_census[:,3] = label_encoder_education.fit_transform(X_census[:,3])
X_census[:,5] = label_encoder_marital.fit_transform(X_census[:,5])
X_census[:,6] = label_encoder_occupation.fit_transform(X_census[:,6])
X_census[:,7] = label_encoder_relationship.fit_transform(X_census[:,7])
X_census[:,8] = label_encoder_race.fit_transform(X_census[:,8])
X_census[:,9] = label_encoder_sex.fit_transform(X_census[:,9])
X_census[:,13] = label_encoder_country.fit_transform(X_census[:,13])

X_census[0]

X_census

"""### OneHotEncoder"""

# Carro

# Gol Pálio Uno
#   1     2   3

# Gol   1 0 0
# Pálio 0 1 0
# Uno   0 0 1 # encode

len(np.unique(base_census['workclass'])) # 1 0 0 0 0 0 0 0, 0 0 0 0 1 0 0 0 0

len(np.unique(base_census['occupation']))

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

onehotencoder_census = ColumnTransformer(transformers=[('OneHot', OneHotEncoder(), [1,3,5,6,7,8,9,13])], remainder='passthrough')

X_census = onehotencoder_census.fit_transform(X_census).toarray()

X_census

X_census[0]

X_census.shape

"""## Escalonamento dos valores"""

from sklearn.preprocessing import StandardScaler
scaler_census = StandardScaler()
X_census = scaler_census.fit_transform(X_census)

X_census[0]

"""# Divisão das bases em treinamento e teste"""

from sklearn.model_selection import train_test_split

"""## Credit data"""

X_credit_treinamento, X_credit_teste, y_credit_treinamento, y_credit_teste = train_test_split(X_credit, y_credit, test_size = 0.25, random_state = 0)

X_credit_treinamento.shape

y_credit_treinamento.shape

X_credit_teste.shape, y_credit_teste.shape

"""## Census"""

X_census_treinamento, X_census_teste, y_census_treinamento, y_census_teste = train_test_split(X_census, y_census, test_size = 0.15, random_state = 0)

X_census_treinamento.shape, y_census_treinamento.shape

X_census_teste.shape, y_census_teste.shape

"""## Salvar as variáveis"""

import pickle

with open('credit.pkl', mode = 'wb') as f:
  pickle.dump([X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste], f)

with open('census.pkl', mode = 'wb') as f:
  pickle.dump([X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste], f)

"""# Naïve Bayes"""

from sklearn.naive_bayes import GaussianNB

"""## Base risco de crédito"""

base_risco_credito = pd.read_csv('/content/risco_credito.csv')

base_risco_credito

X_risco_credito = base_risco_credito.iloc[:, 0:4].values
X_risco_credito

y_risco_credito = base_risco_credito.iloc[:, 4].values
y_risco_credito

from sklearn.preprocessing import LabelEncoder
label_encoder_historia = LabelEncoder()
label_encoder_divida = LabelEncoder()
label_encoder_garantia = LabelEncoder()
label_encoder_renda = LabelEncoder()

X_risco_credito[:,0] = label_encoder_historia.fit_transform(X_risco_credito[:,0])
X_risco_credito[:,1] = label_encoder_divida.fit_transform(X_risco_credito[:,1])
X_risco_credito[:,2] = label_encoder_garantia.fit_transform(X_risco_credito[:,2])
X_risco_credito[:,3] = label_encoder_renda.fit_transform(X_risco_credito[:,3])

X_risco_credito

import pickle
with open('risco_credito.pkl', 'wb') as f:
  pickle.dump([X_risco_credito, y_risco_credito], f)

naive_risco_credito = GaussianNB()
naive_risco_credito.fit(X_risco_credito, y_risco_credito)

# história boa (0), dívida alta (0), garantias nenhuma (1), renda > 35 (2)
# história ruim (2), dívida alta (0), garantias adequada (0), renda < 15 (0)
previsao = naive_risco_credito.predict([[0,0,1,2], [2,0,0,0]])

previsao

naive_risco_credito.classes_

naive_risco_credito.class_count_

naive_risco_credito.class_prior_

"""## Base credit data - 93.80%"""

import pickle
with open('/content/census.pkl', 'rb') as f:
  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)

X_credit_treinamento.shape, y_credit_treinamento.shape

X_credit_teste.shape, y_credit_teste.shape

naive_credit_data = GaussianNB()
naive_credit_data.fit(X_credit_treinamento, y_credit_treinamento)

previsoes = naive_credit_data.predict(X_credit_teste)

previsoes

y_credit_teste

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

accuracy_score(y_credit_teste, previsoes)

confusion_matrix(y_credit_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix

cm = ConfusionMatrix(naive_credit_data)
cm.fit(X_credit_treinamento, y_credit_treinamento)
cm.score(X_credit_teste, y_credit_teste)

print(classification_report(y_credit_teste, previsoes))

"""## Base census - 47.67%"""

with open('census.pkl', 'rb') as f:
  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)

X_census_treinamento.shape, y_census_treinamento.shape

X_census_teste.shape, y_census_teste.shape

naive_census = GaussianNB()
naive_census.fit(X_census_treinamento, y_census_treinamento)
previsoes = naive_census.predict(X_census_teste)
previsoes

y_census_teste

accuracy_score(y_census_teste, previsoes) # não executar o escalonamento

cm = ConfusionMatrix(naive_census)
cm.fit(X_census_treinamento, y_census_treinamento)
cm.score(X_census_teste, y_census_teste)

print(classification_report(y_census_teste, previsoes))

"""# Árvores de decisão"""

from sklearn.tree import DecisionTreeClassifier

"""## Base risco de crédito"""

import pickle
with open('risco_credito.pkl', 'rb') as f:
  X_risco_credito, y_risco_credito = pickle.load(f)

X_risco_credito

y_risco_credito

arvore_risco_credito = DecisionTreeClassifier(criterion='entropy')
arvore_risco_credito.fit(X_risco_credito, y_risco_credito)

arvore_risco_credito.feature_importances_

arvore_risco_credito.classes_

from sklearn import tree
previsores = ['história', 'dívida', 'garantias', 'renda']
figura, eixos = plt.subplots(nrows=1, ncols=1, figsize=(10,10))
tree.plot_tree(arvore_risco_credito, feature_names=previsores, class_names = arvore_risco_credito.classes_, filled=True);

# história boa, dívida alta, garantias nenhuma, renda > 35
# história ruim, dívida alta, garantias adequada, renda < 15
previsoes = arvore_risco_credito.predict([[0,0,1,2],[2,0,0,0]])
previsoes

"""## Base credit data - 98.20%"""

with open('credit.pkl', 'rb') as f:  
  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)

X_credit_treinamento.shape, y_credit_treinamento.shape

X_credit_teste.shape, y_credit_teste.shape

arvore_credit = DecisionTreeClassifier(criterion='entropy', random_state = 0)
arvore_credit.fit(X_credit_treinamento, y_credit_treinamento)

previsoes = arvore_credit.predict(X_credit_teste)
previsoes

y_credit_teste

from sklearn.metrics import accuracy_score, classification_report

accuracy_score(y_credit_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(arvore_credit)
cm.fit(X_credit_treinamento, y_credit_treinamento)
cm.score(X_credit_teste, y_credit_teste)

print(classification_report(y_credit_teste, previsoes))

arvore_credit.classes_

from sklearn import tree
previsores = ['income', 'age', 'loan']
fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (20,20))
tree.plot_tree(arvore_credit, feature_names=previsores, class_names=['0','1'], filled=True);
fig.savefig('arvore_credit.png')

"""## Base census - 81.04%"""

with open('census.pkl', 'rb') as f:  
  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)

X_census_treinamento.shape, y_census_treinamento.shape

X_census_teste.shape, y_census_teste.shape

arvore_census = DecisionTreeClassifier(criterion='entropy', random_state=0)
arvore_census.fit(X_census_treinamento, y_census_treinamento)

previsoes = arvore_census.predict(X_census_teste)
previsoes

y_census_teste

accuracy_score(y_census_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix

from yellowbrick.classifier import ConfusionMatrix
#cm = ConfusionMatrix(arvore_credit) corrigido 10/04/2021
cm = ConfusionMatrix(arvore_census)
cm.fit(X_census_treinamento, y_census_treinamento)
cm.score(X_census_teste, y_census_teste)

print(classification_report(y_census_teste, previsoes))

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier

"""## Base credit data - 98.40%"""

import pickle
with open('credit.pkl', 'rb') as f:  
  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)

X_credit_treinamento.shape, y_credit_treinamento.shape

X_credit_teste.shape, y_credit_teste.shape

random_forest_credit = RandomForestClassifier(n_estimators=40, criterion='entropy', random_state = 0)
random_forest_credit.fit(X_credit_treinamento, y_credit_treinamento)

previsoes = random_forest_credit.predict(X_credit_teste)
previsoes

y_credit_teste

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_credit_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(random_forest_credit)
cm.fit(X_credit_treinamento, y_credit_treinamento)
cm.score(X_credit_teste, y_credit_teste)

print(classification_report(y_credit_teste, previsoes))

"""## Base census - 85.07%"""

with open('census.pkl', 'rb') as f:  
  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)

X_census_treinamento.shape, y_census_treinamento.shape

X_census_teste.shape, y_census_teste.shape

y_census_treinamento

random_forest_census = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state = 0)
random_forest_census.fit(X_census_treinamento, y_census_treinamento)

previsoes = random_forest_census.predict(X_census_teste)
previsoes

y_census_teste

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_census_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(random_forest_census)
cm.fit(X_census_treinamento, y_census_treinamento)
cm.score(X_census_teste, y_census_teste)

print(classification_report(y_census_teste, previsoes))

"""# Regras"""

!pip install Orange3

import Orange

"""## Base risco de crédito"""

base_risco_credito = Orange.data.Table('risco_credito_regras.csv')

base_risco_credito

base_risco_credito.domain

cn2 = Orange.classification.rules.CN2Learner()
regras_risco_credito = cn2(base_risco_credito)

for regras in regras_risco_credito.rule_list:
  print(regras)

# história boa, dívida alta, garantias nenhuma, renda > 35
# história ruim, dívida alta, garantias adequada, renda < 15
previsoes = regras_risco_credito([['boa', 'alta', 'nenhuma', 'acima_35'], ['ruim', 'alta', 'adequada', '0_15']])
previsoes

base_risco_credito.domain.class_var.values

for i in previsoes:
  #print(i)
  print(base_risco_credito.domain.class_var.values[i])

"""## Base credit data - 97.40%"""

base_credit = Orange.data.Table('/content/credit_data_regras.csv')

base_credit.domain

base_dividida = Orange.evaluation.testing.sample(base_credit, n = 0.25)

base_dividida

base_dividida[0]

base_dividida[1]

base_treinamento = base_dividida[1]
base_teste = base_dividida[0]

len(base_treinamento), len(base_teste)

cn2 = Orange.classification.rules.CN2Learner()
regras_credit = cn2(base_treinamento)

for regras in regras_credit.rule_list:
  print(regras)

previsoes = Orange.evaluation.testing.TestOnTestData(base_treinamento, base_teste, [lambda testdata: regras_credit])

previsoes

Orange.evaluation.CA(previsoes)

"""## Base census - 78.90% (executado na interface gráfica do Orange)

# Classificador base - Majority learner

## Base credit data - 85.85%
"""

base_credit = Orange.data.Table('credit_data_regras.csv')

base_credit.domain

majority = Orange.classification.MajorityLearner()

previsoes = Orange.evaluation.testing.TestOnTestData(base_credit, base_credit, [majority])

Orange.evaluation.CA(previsoes)

for registro in base_credit:
  print(registro.get_class())

from collections import Counter
Counter(str(registro.get_class()) for registro in base_credit)

1717 / 2000

"""## Base census - 75.91%"""

base_census = Orange.data.Table('census_regras.csv')

base_census.domain

majority = Orange.classification.MajorityLearner()
previsoes = Orange.evaluation.testing.TestOnTestData(base_census, base_census, [majority])
Orange.evaluation.CA(previsoes)

Counter(str(registro.get_class()) for registro in base_census)

24720 / (24720 + 7841)

"""# Aprendizagem baseada em instâncias - knn"""

from sklearn.neighbors import KNeighborsClassifier

"""## Base credit data - 98.60%"""

import pickle
with open('credit.pkl', 'rb') as f:  
  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)

X_credit_treinamento.shape, y_credit_treinamento.shape

X_credit_teste.shape, y_credit_teste.shape

knn_credit = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p = 2)
knn_credit.fit(X_credit_treinamento, y_credit_treinamento)

previsoes = knn_credit.predict(X_credit_teste)
previsoes

y_credit_teste

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_credit_teste, previsoes) # padronização

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(knn_credit)
cm.fit(X_credit_treinamento, y_credit_treinamento)
cm.score(X_credit_teste, y_credit_teste)

print(classification_report(y_credit_teste, previsoes))

"""## Base census - 82.90%"""

with open('census.pkl', 'rb') as f:  
  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)

X_census_treinamento.shape, y_census_treinamento.shape

X_census_teste.shape, y_census_teste.shape

knn_census = KNeighborsClassifier(n_neighbors=10)
knn_census.fit(X_census_treinamento, y_census_treinamento)

previsoes = knn_census.predict(X_census_teste)
previsoes

y_census_teste

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_census_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(knn_census)
cm.fit(X_census_treinamento, y_census_treinamento)
cm.score(X_census_teste, y_census_teste)

print(classification_report(y_census_teste, previsoes))

"""# Regressão logística"""

from sklearn.linear_model import LogisticRegression

"""## Base risco de crédito"""

import pickle
with open('risco_credito.pkl', 'rb') as f:  
  X_risco_credito, y_risco_credito = pickle.load(f)

X_risco_credito

y_risco_credito # 2, 7, 11

X_risco_credito = np.delete(X_risco_credito, [2, 7, 11], axis = 0)
y_risco_credito = np.delete(y_risco_credito, [2, 7, 11], axis = 0)

X_risco_credito

y_risco_credito

logistic_risco_credito = LogisticRegression(random_state = 1)
logistic_risco_credito.fit(X_risco_credito, y_risco_credito)

logistic_risco_credito.intercept_

logistic_risco_credito.coef_

# história boa, dívida alta, garantias nenhuma, renda > 35
# história ruim, dívida alta, garantias adequada, renda < 15
previsoes1 = logistic_risco_credito.predict([[0,0,1,2], [2,0,0,0]])
previsoes1

"""## Base credit data - 94.60%"""

import pickle
with open('credit.pkl', 'rb') as f:  
  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)

X_credit_treinamento.shape, y_credit_treinamento.shape

X_credit_teste.shape, y_credit_teste.shape

logistic_credit = LogisticRegression(random_state=1)
logistic_credit.fit(X_credit_treinamento, y_credit_treinamento)

logistic_credit.intercept_

logistic_credit.coef_

previsoes = logistic_credit.predict(X_credit_teste)
previsoes

y_credit_teste

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_credit_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(logistic_credit)
cm.fit(X_credit_treinamento, y_credit_treinamento)
cm.score(X_credit_teste, y_credit_teste)

print(classification_report(y_credit_teste, previsoes))

"""## Base census - 84.95%"""

with open('census.pkl', 'rb') as f:  
  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)

X_census_treinamento.shape, y_census_treinamento.shape

X_census_teste.shape, y_census_teste.shape

logistic_census = LogisticRegression(random_state = 1)
logistic_census.fit(X_census_treinamento, y_census_treinamento)

previsoes = logistic_census.predict(X_census_teste)
previsoes

y_census_teste

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_census_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(logistic_census)
cm.fit(X_census_treinamento, y_census_treinamento)
cm.score(X_census_teste, y_census_teste)

print(classification_report(y_census_teste, previsoes))

"""# SVM"""

from sklearn.svm import SVC

"""## Base credit data - 98.80%"""

import pickle
with open('credit.pkl', 'rb') as f:  
  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)

X_credit_treinamento.shape, y_credit_treinamento.shape

X_credit_teste.shape, y_credit_teste.shape

svm_credit = SVC(kernel='rbf', random_state=1, C = 2.0) # 2 -> 4
svm_credit.fit(X_credit_treinamento, y_credit_treinamento)

previsoes = svm_credit.predict(X_credit_teste)
previsoes

y_credit_teste

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_credit_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(svm_credit)
cm.fit(X_credit_treinamento, y_credit_treinamento)
cm.score(X_credit_teste, y_credit_teste)

print(classification_report(y_credit_teste, previsoes))

"""## Base census - 85.07%"""

with open('census.pkl', 'rb') as f:  
  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)

X_census_treinamento.shape, y_census_treinamento.shape

X_census_teste.shape, y_census_teste.shape

svm_census = SVC(kernel='linear', random_state=1)
svm_census.fit(X_census_treinamento, y_census_treinamento)

previsoes = svm_census.predict(X_census_teste)
previsoes

y_census_teste

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_census_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(svm_census)
cm.fit(X_census_treinamento, y_census_treinamento)
cm.score(X_census_teste, y_census_teste)

print(classification_report(y_census_teste, previsoes))

"""# Redes neurais artificiais"""

from sklearn.neural_network import MLPClassifier

"""## Base credit data - 99.80%"""

import pickle
with open('credit.pkl', 'rb') as f:  
  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)

X_credit_treinamento.shape, y_credit_treinamento.shape

X_credit_teste.shape, y_credit_teste.shape

(3 + 1) / 2

# 3 -> 100 -> 100 -> 1
# 3 -> 2 -> 2 -> 1
rede_neural_credit = MLPClassifier(max_iter=1500, verbose=True, tol=0.0000100,
                                   solver = 'adam', activation = 'relu',
                                   hidden_layer_sizes = (20,20))
rede_neural_credit.fit(X_credit_treinamento, y_credit_treinamento)

previsoes = rede_neural_credit.predict(X_credit_teste)
previsoes

y_credit_teste

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_credit_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(rede_neural_credit)
cm.fit(X_credit_treinamento, y_credit_treinamento)
cm.score(X_credit_teste, y_credit_teste)

print(classification_report(y_credit_teste, previsoes))

"""## Base census - 81.53%"""

with open('census.pkl', 'rb') as f:  
  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)

X_census_treinamento.shape, y_census_treinamento.shape

X_census_teste.shape, y_census_teste.shape

(108 + 1) / 2

# 108 -> 55 -> 55 -> 1
rede_neural_census = MLPClassifier(verbose=True, max_iter = 1000, tol=0.000010,
                                  hidden_layer_sizes = (55,55))
rede_neural_census.fit(X_census_treinamento, y_census_treinamento)

previsoes = rede_neural_census.predict(X_census_teste)
previsoes

y_census_teste

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_census_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(rede_neural_census)
cm.fit(X_census_treinamento, y_census_treinamento)
cm.score(X_census_teste, y_census_teste)

print(classification_report(y_census_teste, previsoes))

"""# Avaliação dos algoritmos

- Naïve Bayes: 93.80
- Árvore de decisão: 98.20
- Random forest: 98.40
- Regras: 97.40
- Knn: 98.60
- Regressão logística: 94.60
- SVM: 98.80
- Redes neurais: 99.60

## Tuning dos parâmetros com GridSearch

### Preparação dos dados
"""

from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier

import pickle
with open('credit.pkl', 'rb') as f:  
  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)

X_credit_treinamento.shape, y_credit_treinamento.shape

X_credit_teste.shape, y_credit_teste.shape

X_credit = np.concatenate((X_credit_treinamento, X_credit_teste), axis = 0)
X_credit.shape

X_credit

y_credit = np.concatenate((y_credit_treinamento, y_credit_teste), axis = 0)
y_credit.shape

y_credit

"""### Árvore de decisão"""

parametros = {'criterion': ['gini', 'entropy'],
              'splitter': ['best', 'random'],
              'min_samples_split': [2, 5, 10],
              'min_samples_leaf': [1, 5, 10]}

grid_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=parametros)
grid_search.fit(X_credit, y_credit)
melhores_parametros = grid_search.best_params_
melhor_resultado = grid_search.best_score_
print(melhores_parametros)
print(melhor_resultado)

"""### Random forest"""

parametros = {'criterion': ['gini', 'entropy'],
              'n_estimators': [10, 40, 100, 150],
              'min_samples_split': [2, 5, 10],
              'min_samples_leaf': [1, 5, 10]}

grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parametros)
grid_search.fit(X_credit, y_credit)
melhores_parametros = grid_search.best_params_
melhor_resultado = grid_search.best_score_
print(melhores_parametros)
print(melhor_resultado)

"""### Knn"""

parametros = {'n_neighbors': [3, 5, 10, 20],
              'p': [1, 2]}

grid_search = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=parametros)
grid_search.fit(X_credit, y_credit)
melhores_parametros = grid_search.best_params_
melhor_resultado = grid_search.best_score_
print(melhores_parametros)
print(melhor_resultado)

"""### Regressão logística"""

parametros = {'tol': [0.0001, 0.00001, 0.000001],
              'C': [1.0, 1.5, 2.0],
              'solver': ['lbfgs', 'sag', 'saga']}

grid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=parametros)
grid_search.fit(X_credit, y_credit)
melhores_parametros = grid_search.best_params_
melhor_resultado = grid_search.best_score_
print(melhores_parametros)
print(melhor_resultado)

"""### SVM"""

parametros = {'tol': [0.001, 0.0001, 0.00001],
              'C': [1.0, 1.5, 2.0],
              'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}

grid_search = GridSearchCV(estimator=SVC(), param_grid=parametros)
grid_search.fit(X_credit, y_credit)
melhores_parametros = grid_search.best_params_
melhor_resultado = grid_search.best_score_
print(melhores_parametros)
print(melhor_resultado)

"""### Redes neurais"""

parametros = {'activation': ['relu', 'logistic', 'tahn'],
              'solver': ['adam', 'sgd'],
              'batch_size': [10, 56]}

grid_search = GridSearchCV(estimator=MLPClassifier(), param_grid=parametros)
grid_search.fit(X_credit, y_credit)
melhores_parametros = grid_search.best_params_
melhor_resultado = grid_search.best_score_

print(melhores_parametros)
print(melhor_resultado)

"""## Validação cruzada"""

from sklearn.model_selection import cross_val_score, KFold

10 * 30

resultados_arvore = []
resultados_random_forest = []
resultados_knn = []
resultados_logistica = []
resultados_svm = []
resultados_rede_neural = []

for i in range(30):
  print(i)
  kfold = KFold(n_splits=10, shuffle=True, random_state=i)

  arvore = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=1, min_samples_split=5, splitter='best')
  scores = cross_val_score(arvore, X_credit, y_credit, cv = kfold)
  #print(scores)
  #print(scores.mean())
  resultados_arvore.append(scores.mean())

  random_forest = RandomForestClassifier(criterion = 'entropy', min_samples_leaf = 1, min_samples_split=5, n_estimators = 10)
  scores = cross_val_score(random_forest, X_credit, y_credit, cv = kfold)
  resultados_random_forest.append(scores.mean())

  knn = KNeighborsClassifier()
  scores = cross_val_score(knn, X_credit, y_credit, cv = kfold)
  resultados_knn.append(scores.mean())

  logistica = LogisticRegression(C = 1.0, solver = 'lbfgs', tol = 0.0001)
  scores = cross_val_score(logistica, X_credit, y_credit, cv = kfold)
  resultados_logistica.append(scores.mean())

  svm = SVC(kernel = 'rbf', C = 2.0)
  scores = cross_val_score(svm, X_credit, y_credit, cv = kfold)
  resultados_svm.append(scores.mean())

  rede_neural = MLPClassifier(activation = 'relu', batch_size = 56, solver = 'adam')
  scores = cross_val_score(rede_neural, X_credit, y_credit, cv = kfold)
  resultados_rede_neural.append(scores.mean())

resultados = pd.DataFrame({'Arvore': resultados_arvore, 'Random forest': resultados_random_forest,
                           'KNN': resultados_knn, 'Logistica': resultados_logistica,
                           'SVM': resultados_svm, 'Rede neural': resultados_rede_neural})
resultados

resultados.describe()

resultados.var()

(resultados.std() / resultados.mean()) * 100

"""## Teste de normalidade nos resultados

- Shapiro: https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test
"""

alpha = 0.05

from scipy.stats import shapiro

shapiro(resultados_arvore), shapiro(resultados_random_forest), shapiro(resultados_knn), shapiro(resultados_logistica), shapiro(resultados_svm), shapiro(resultados_rede_neural)

sns.displot(resultados_arvore, kind = 'kde');

sns.displot(resultados_random_forest, kind = 'kde');

sns.displot(resultados_knn, kind = 'kde');

sns.displot(resultados_logistica, kind = 'kde');

sns.displot(resultados_svm, kind = 'kde');

sns.displot(resultados_rede_neural, kind = 'kde');

"""## Teste de hipótese com ANOVA e Tukey"""

from scipy.stats import f_oneway

_, p = f_oneway(resultados_arvore, resultados_random_forest, resultados_knn, resultados_logistica, resultados_svm, resultados_rede_neural)
p

alpha = 0.05
if p <= alpha:
  print('Hipótese nula rejeitada. Dados são diferentes')
else:
  print('Hipótese alternativa rejeitada. Resultados são iguais')

resultados_algoritmos = {'accuracy': np.concatenate([resultados_arvore, resultados_random_forest, resultados_knn, resultados_logistica, resultados_svm, resultados_rede_neural]),
                         'algoritmo': ['arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore','arvore', 
                          'random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest','random_forest', 
                          'knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn','knn', 
                          'logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica',
                          'svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm',
                          'rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural']}

resultados_df = pd.DataFrame(resultados_algoritmos)
resultados_df

from statsmodels.stats.multicomp import MultiComparison

compara_algoritmos = MultiComparison(resultados_df['accuracy'], resultados_df['algoritmo'])

teste_estatistico = compara_algoritmos.tukeyhsd()
print(teste_estatistico)

resultados.mean()

teste_estatistico.plot_simultaneous();

"""# Salvar um classificador já treinado"""

with open('credit.pkl', 'rb') as f:  
  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)

X_credit = np.concatenate((X_credit_treinamento, X_credit_teste), axis = 0)
y_credit = np.concatenate((y_credit_treinamento, y_credit_teste), axis = 0)

X_credit.shape, y_credit.shape

from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

classificador_rede_neural = MLPClassifier(activation='relu', batch_size = 56, solver='adam')
classificador_rede_neural.fit(X_credit, y_credit)

classificador_arvore = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=1, min_samples_split=5, splitter='best')
classificador_arvore.fit(X_credit, y_credit)

classificador_svm = SVC(C = 2.0, kernel='rbf', probability=True)
classificador_svm.fit(X_credit, y_credit)

import pickle
pickle.dump(classificador_rede_neural, open('rede_neural_finalizado.sav', 'wb'))
pickle.dump(classificador_arvore, open('arvore_finalizado.sav', 'wb'))
pickle.dump(classificador_svm, open('svm_finalizado.sav', 'wb'))

"""# Carregar um classificador já treinado"""

rede_neural = pickle.load(open('rede_neural_finalizado.sav', 'rb'))
arvore = pickle.load(open('arvore_finalizado.sav', 'rb'))
svm = pickle.load(open('svm_finalizado.sav', 'rb'))

novo_registro = X_credit[1999]
novo_registro

novo_registro.shape

novo_registro = novo_registro.reshape(1, -1)
novo_registro.shape

novo_registro

rede_neural.predict(novo_registro)

arvore.predict(novo_registro)

svm.predict(novo_registro)

"""# Combinação de classificadores"""

novo_registro = X_credit[1999]
novo_registro = novo_registro.reshape(1, -1)
novo_registro, novo_registro.shape

resposta_rede_neural = rede_neural.predict(novo_registro)
resposta_arvore = arvore.predict(novo_registro)
resposta_svm = svm.predict(novo_registro)

resposta_rede_neural[0], resposta_arvore[0], resposta_svm[0]

paga = 0
nao_paga = 0

if resposta_rede_neural[0] == 1:
  nao_paga += 1
else:
  paga += 1

if resposta_arvore[0] == 1:
  nao_paga += 1
else:
  paga += 1

if resposta_svm[0] == 1:
  nao_paga += 1
else:
  paga += 1

if paga > nao_paga:
  print('Cliente pagará o empréstimo')
elif paga == nao_paga:
  print('Empate')
else:
  print('Cliente não pagará o empréstimo')

"""# Rejeição de classificadores"""

novo_registro = X_credit[1999]
novo_registro = novo_registro.reshape(1, -1)
novo_registro, novo_registro.shape

resposta_rede_neural = rede_neural.predict(novo_registro)
resposta_arvore = arvore.predict(novo_registro)
resposta_svm = svm.predict(novo_registro)

resposta_rede_neural[0], resposta_arvore[0], resposta_svm[0]

probabilidade_rede_neural = rede_neural.predict_proba(novo_registro)
probabilidade_rede_neural

confianca_rede_neural = probabilidade_rede_neural.max()
confianca_rede_neural

probabilidade_arvore = arvore.predict_proba(novo_registro)
confianca_arvore = probabilidade_arvore.max()
confianca_arvore

probabilidade_svm = svm.predict_proba(novo_registro)
confianca_svm = probabilidade_svm.max()
confianca_svm

paga = 0
nao_paga = 0
confianca_minima = 0.999999
algoritmos = 0

if confianca_rede_neural >= confianca_minima:
  algoritmos += 1
  if resposta_rede_neural[0] == 1:
    nao_paga += 1
  else:
    paga += 1

if confianca_arvore >= confianca_minima:
  algoritmos += 1
  if resposta_arvore[0] == 1:
    nao_paga += 1
  else:
    paga += 1

if confianca_svm >= confianca_minima:
  algoritmos += 1
  if resposta_svm[0] == 1:
    nao_paga += 1
  else:
    paga += 1

if paga > nao_paga:
  print('Cliente pagará o empréstimo, baseado em {} algoritmos'.format(algoritmos))
elif paga == nao_paga:
  print('Empate, baseado em {} algoritmos'.format(algoritmos))
else:
  print('Cliente não pagará o empréstimo, baseado em {} algoritmos'.format(algoritmos))

"""# Redução de dimensionalidade

## Preparacão da base de dados
"""

base_census = pd.read_csv('/content/census.csv')
base_census

X_census = base_census.iloc[:, 0:14].values
X_census

y_census = base_census.iloc[:, 14].values
y_census

from sklearn.preprocessing import LabelEncoder
label_encoder_workclass = LabelEncoder()
label_encoder_education = LabelEncoder()
label_encoder_marital = LabelEncoder()
label_encoder_occupation = LabelEncoder()
label_encoder_relationship = LabelEncoder()
label_encoder_race = LabelEncoder()
label_encoder_sex = LabelEncoder()
label_encoder_country = LabelEncoder()

X_census[:,1] = label_encoder_workclass.fit_transform(X_census[:,1])
X_census[:,3] = label_encoder_education.fit_transform(X_census[:,3])
X_census[:,5] = label_encoder_marital.fit_transform(X_census[:,5])
X_census[:,6] = label_encoder_occupation.fit_transform(X_census[:,6])
X_census[:,7] = label_encoder_relationship.fit_transform(X_census[:,7])
X_census[:,8] = label_encoder_race.fit_transform(X_census[:,8])
X_census[:,9] = label_encoder_sex.fit_transform(X_census[:,9])
X_census[:,13] = label_encoder_country.fit_transform(X_census[:,13])

X_census[0]

from sklearn.preprocessing import StandardScaler
scaler_census = StandardScaler()
X_census = scaler_census.fit_transform(X_census)

X_census

from sklearn.model_selection import train_test_split
X_census_treinamento, X_census_teste, y_census_treinamento, y_census_teste = train_test_split(X_census, y_census, test_size=0.15, random_state=0)

X_census_treinamento.shape, X_census_teste.shape

"""## PCA (Principal component analysis)"""

from sklearn.decomposition import PCA

pca = PCA(n_components=8)

X_census_treinamento_pca = pca.fit_transform(X_census_treinamento)
X_census_testes_pca = pca.transform(X_census_teste)

X_census_treinamento_pca.shape, X_census_testes_pca.shape

X_census_treinamento

pca.explained_variance_ratio_

pca.explained_variance_ratio_.sum()

from sklearn.ensemble import RandomForestClassifier

random_forest_census_pca = RandomForestClassifier(n_estimators=40, random_state=0, criterion = 'entropy')
random_forest_census_pca.fit(X_census_treinamento_pca, y_census_treinamento)

previsoes = random_forest_census_pca.predict(X_census_testes_pca)
previsoes

y_census_teste

from sklearn.metrics import accuracy_score
accuracy_score(y_census_teste, previsoes)

"""## Kernel PCA"""

from sklearn.decomposition import KernelPCA

kpca = KernelPCA(n_components=8, kernel='rbf')
X_census_treinamento_kpca = kpca.fit_transform(X_census_treinamento)
X_census_teste_kpca = kpca.transform(X_census_teste)

X_census_treinamento_kpca.shape, X_census_teste_kpca.shape

X_census_treinamento_kpca

from sklearn.ensemble import RandomForestClassifier
random_forest_census_kpca = RandomForestClassifier(n_estimators = 40, criterion = 'entropy', random_state = 0)
random_forest_census_kpca.fit(X_census_treinamento_kpca, y_census_treinamento)

previsoes = random_forest_census_kpca.predict(X_census_teste_kpca)
previsoes

y_census_teste

from sklearn.metrics import accuracy_score
accuracy_score(y_census_teste, previsoes)

"""## LDA (Linear discriminant analysis)"""

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
lda = LinearDiscriminantAnalysis(n_components = 8)

X_census_treinamento_lda = lda.fit_transform(X_census_treinamento, y_census_treinamento)
X_census_teste_lda = lda.transform(X_census_teste)

X_census_treinamento_lda.shape, X_census_teste_lda.shape

X_census_treinamento_lda

from sklearn.ensemble import RandomForestClassifier
random_forest_census_lda = RandomForestClassifier(n_estimators = 40, criterion = 'entropy', random_state = 0)
random_forest_census_lda.fit(X_census_treinamento_lda, y_census_treinamento)

previsoes = random_forest_census_lda.predict(X_census_teste_lda)
previsoes

y_census_teste

from sklearn.metrics import accuracy_score
accuracy_score(y_census_teste, previsoes)

"""# Detecção de outliers

## Boxplot
"""

base_credit = pd.read_csv('credit_data.csv')
base_credit

base_credit.isnull().sum()

base_credit.dropna(inplace=True)

base_credit.isnull().sum()

1997 / 2

# Outliers idade
grafico = px.box(base_credit, y = 'age')
grafico.show()

outliers_age = base_credit[base_credit['age'] < 0]
outliers_age

# Outliers loan
grafico = px.box(base_credit, y='loan')
grafico.show()

outliers_loan = base_credit[base_credit['loan'] > 13300]
outliers_loan

"""## Gráfico de dispersão"""

# Income x age
grafico = px.scatter(x = base_credit['income'], y = base_credit['age'])
grafico.show()

# Income x loan
grafico = px.scatter(x = base_credit['income'], y = base_credit['loan'])
grafico.show()

# Age x loan
grafico = px.scatter(x = base_credit['age'], y = base_credit['loan'])
grafico.show()

base_census = pd.read_csv('census.csv')
base_census

# Age x final weight
grafico = px.scatter(x = base_census['age'], y = base_census['final-weight'])
grafico.show()

"""## Biblioteca PyOD

- Documentação: https://pyod.readthedocs.io/en/latest/#
"""

!pip install pyod

from pyod.models.knn import KNN

base_credit.head(1)

detector = KNN()
detector.fit(base_credit.iloc[:,1:4])

previsoes = detector.labels_
previsoes

np.unique(previsoes, return_counts=True)

confianca_previsoes = detector.decision_scores_
confianca_previsoes

outliers = []
for i in range(len(previsoes)):
  #print(i)
  if previsoes[i] == 1:
    outliers.append(i)

print(outliers)

lista_outliers = base_credit.iloc[outliers,:]
lista_outliers